{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40467f2",
   "metadata": {},
   "source": [
    "This notebook file contains all the code used for the fetching, processing and splitting of the data. Data and results can be found in the offically used data folder. This file is a cleaned up version of the file the experiments were run in. I kept that file accesible in the legacy code folder as \"traintest_legacy.ipynb\", but this file contains all the useful code with none of the errant test functions and print statements. I also added more comments to this file for readability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06029816",
   "metadata": {},
   "source": [
    "This file was created so that both models would have the exact same training and test data, and that the test data would also be split the same way into x_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbdfe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrosm.data import sources\n",
    "import pyrosm\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tags(val):\n",
    "    \"\"\"\n",
    "    This code is used to quickly parse through the data once as we get it and remove any odd or missing values\n",
    "    \"\"\"\n",
    "    if pd.isna(val) or val in [\"None\", \"nan\", None]:\n",
    "        return {}\n",
    "    try:\n",
    "        return ast.literal_eval(val) if isinstance(val, str) else val\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "def create_tag_lists(pois, n):\n",
    "    \"\"\"\n",
    "    Returns all_good_tags, a list of the tags that appear more than n\n",
    "    Returns tag2idx, a dictionary linking every allowed tag to an index number\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_freq = defaultdict(int)\n",
    "\n",
    "    for idx, row in pois.iterrows(): \n",
    "        tags = row.get(\"tags\", {})\n",
    "        \n",
    "        # Counting the frequency of tags\n",
    "        # This was also used for creating some graphs for analysis\n",
    "        if isinstance(tags, dict) and tags:\n",
    "            for tag_key in tags:\n",
    "                tag_freq[tag_key] += 1\n",
    "\n",
    "    # All good tags are the tags that have a higher frequency than N \n",
    "    all_tags = list(tag_freq.keys())\n",
    "    all_good_tags = [tag for tag in tag_freq if tag_freq[tag] > n]\n",
    "\n",
    "    # tag2idx and idx2tag arent used in this notebook\n",
    "    # This function was originally only for random forest, where it would also vectorize objects\n",
    "    # I was kinda too lazy to create two functions so half of the function is only utilized here while the other half of the function is used there\n",
    "    tag2idx = {tag: i for i, tag in enumerate(all_good_tags)}\n",
    "    idx2tag = {i: tag for tag, i in tag2idx.items()}\n",
    "\n",
    "\n",
    "    tag_freq = dict(sorted(tag_freq.items(), key = lambda x: x[1], reverse = True))\n",
    "    print(f\"All tags sorted by frequency: {tag_freq}\")\n",
    "    print(f\" All allowed tags: {all_good_tags}\")\n",
    "    print(f\"Len all tags: {len(all_tags)}, Len good tags: {len(all_good_tags)}\")\n",
    "\n",
    "    # We only return these two objects\n",
    "    # During testing and in other versions I have returned tag_freq or idx2tag but that wasn't needed for the experiments on random forest\n",
    "    return (all_good_tags, tag2idx)\n",
    "\n",
    "def remove_bad_tags(good_tags, pois):\n",
    "    \"\"\"\n",
    "    This function removes every tag from pois that is not in good_tags\n",
    "    \"\"\"\n",
    "    for i in pois[\"tags\"]:\n",
    "        remove_list = []\n",
    "        for j in i:\n",
    "            # Checking per object and per tag in that object whether it is in good_tags or not\n",
    "            if j not in good_tags:\n",
    "                remove_list.append(j)\n",
    "        # Once we find all the tags to remove, we remove the tags\n",
    "        for removable in remove_list:\n",
    "            i.pop(removable)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data from pyrosm\n",
    "# I am unsure how often pyrosm or even OSM gets updated but we fetched the data on the 15th of June 2025\n",
    "fp = pyrosm.get_data(\"Amsterdam\")\n",
    "osm = pyrosm.OSM(fp)\n",
    "pois = osm.get_pois()\n",
    "# Quickly parse through the pois\n",
    "pois[\"tags\"] = pois[\"tags\"].apply(parse_tags) #only need to run it once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d52222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of tags for them to be allowed\n",
    "n_good_tags = 10 \n",
    "\n",
    "# Finding and keeping only the good tags\n",
    "good_tags, tag2idx = create_tag_lists(pois, n_good_tags)\n",
    "remove_bad_tags(good_tags, pois)\n",
    "\n",
    "# Keep only rows where 'tags' is more than two\n",
    "pois = pois[pois[\"tags\"].apply(lambda x: isinstance(x, dict) and len(x) > 2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654ccff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data into train and test\n",
    "final_train,  final_test = train_test_split(pois, test_size=0.2)\n",
    "\n",
    "\n",
    "test_questions = []\n",
    "test_answers = []\n",
    "\n",
    "# Taking the last tag off of every object in the test set\n",
    "for i in final_test['tags']:\n",
    "    inew = list(i.keys())\n",
    "    idx = random.randint(0, len(inew)-1)\n",
    "    # This last tag is put into answers while the rest goes into questions\n",
    "    test_answers.append(inew[idx])\n",
    "    test_questions.append(inew[:idx] + inew[idx+1:])\n",
    "\n",
    "print(\"q-a\", len(test_questions), len(test_answers))\n",
    "\n",
    "\n",
    "# Saving the data through pickle\n",
    "# The data used for the experiments is in the officially used data folder\n",
    "with open('trainingset', 'wb') as fp:\n",
    "    pickle.dump(final_train, fp)\n",
    "with open('testset_questions', 'wb') as fb:\n",
    "    pickle.dump(test_questions, fb)\n",
    "with open('testset_answer', 'wb') as fq:\n",
    "    pickle.dump(test_answers, fq)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
