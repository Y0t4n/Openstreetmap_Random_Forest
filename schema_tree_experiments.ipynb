{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c7bd61",
   "metadata": {},
   "source": [
    "This notebook file contains all the code used for the experiments that were done. Data and results can be found in the offically used data folder. This file is a cleaned up version of the file the experiments were run in. I kept that file accesible in the legacy code folder as \"tree_and_server_legacy.ipynb\", but this file contains all the useful code with none of the errant test functions and print statements. I also added more comments to this file for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import subprocess\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from openpyxl import Workbook\n",
    "# For below import to work move convert_report2excel from support files to the same directory as this file\n",
    "from convert_report2excel import convert_report2excel\n",
    "\n",
    "# To run this code it is also important that you clone a local copy of the github project https://github.com/martaannaj/RecommenderServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below functions evolved out of earlier versions that were created when first encountering this project\n",
    "\n",
    "def create_tree_train_set(training_set:dict, tsvfilename:str, path_to_server_dir: str):\n",
    "    \"\"\"\n",
    "    Converts input data to TSV \n",
    "    The creates a tree from that TSV\n",
    "    Takes as input a pois[\"tags\"] column of a pandas geodata object\n",
    "    Meant for use in final experiments\n",
    "    tsvfilename is an input that should stay consistent throughout the experiment, as all corresponding files will be named as such\n",
    "    path_to_server_dir should be the path to a copy of RecommenderServer on github: https://github.com/martaannaj/RecommenderServer\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(tsvfilename, \"w\") as tsvfile:\n",
    "        tsv_writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "        for obj in training_set:\n",
    "            listed = list(obj.keys())\n",
    "            if len(listed) > 0:\n",
    "                # Making sure the list isn't empty, even though it should never be\n",
    "                tsv_writer.writerow(listed)\n",
    "        \n",
    "        tsvfile.close()\n",
    "\n",
    "    # This is the code to query the RecommenderServer to create a tree\n",
    "    result = subprocess.run(['cmd', '/c', 'cd'], capture_output=True, text=True)\n",
    "    subprocess.run(['RecommenderServer', 'build-tree', 'from-tsv', result.stdout.strip() + '/' + tsvfilename], cwd= path_to_server_dir)\n",
    "\n",
    "def multiquery(tsvfilename: str, path_to_server_dir: str, query_list: list[list[str]], n:int = 1) -> list[str]:\n",
    "    \"\"\"\n",
    "    Opens a server and queries it for every property list in query_list without closing the server\n",
    "    Stores the query results in order\n",
    "    n is the amount of tags it should predict for every property list, for our experiments we will keep this 1\n",
    "    \"\"\"\n",
    "\n",
    "    # Below line later used to check our output\n",
    "    _JSON_RE = re.compile(r\"\\{.*\\}\", re.S) \n",
    "    counter = 0\n",
    "    # Open the server\n",
    "    # Once again you need the path to your recommenderServer\n",
    "    open_server = subprocess.Popen(['RecommenderServer', 'serve', tsvfilename + '.schemaTree.typed.pb'], cwd= path_to_server_dir)\n",
    "    response_list = []\n",
    "\n",
    "    for property_list in query_list:\n",
    "        # This is the command that works with Windows Powershell\n",
    "        powershell_command = \"\"\"\n",
    "        $body = '{\"properties\": \"\"\" + property_list + \"\"\",\"types\":[]}'\n",
    "        $response = Invoke-WebRequest -Uri \"http://localhost:8080/recommender\" -Method POST -Body $body -ContentType \"application/json\"\n",
    "        $response.Content\n",
    "        \"\"\"\n",
    "        result = subprocess.run([\"powershell\", \"-Command\", powershell_command], capture_output=True, text=True)\n",
    "        \n",
    "        # This checks if the result is actually there, and gives it some time if it's not\n",
    "        while not _JSON_RE.search(result.stdout) and counter < 10:\n",
    "            time.sleep(1)\n",
    "            counter += 1\n",
    "            result = subprocess.run([\"powershell\", \"-Command\", powershell_command], capture_output=True, text=True)\n",
    "\n",
    "        # Taking the n first recommendations out of the servers' response\n",
    "        parsed = json.loads(result.stdout) \n",
    "        for rec in parsed[\"recommendations\"][:n]:\n",
    "            # Even if it is None, we still need a result in the list for the alignment\n",
    "            if rec[\"property\"] is None:\n",
    "                response_list.append(\"None\")\n",
    "                print(\"None\")\n",
    "            else: \n",
    "                response_list.append(rec[\"property\"])\n",
    "    \n",
    "    # Finally, we terminate the server and return our responses\n",
    "    open_server.terminate()\n",
    "    \n",
    "    return response_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training set to create the tree\n",
    "with open('trainingset', 'rb') as fp:\n",
    "    trainingloaded = pickle.load(fp)\n",
    "# And the test set for querying and answers for checking\n",
    "with open('testset_questions', 'rb') as fp:\n",
    "    questions = pickle.load(fp)\n",
    "with open('testset_answer', 'rb') as fp:\n",
    "    answers = pickle.load(fp)\n",
    "\n",
    "# Path to the RecommenderServer folder\n",
    "path_to_server_dir = \"Put the path to RecommenderServer here\"\n",
    "# Below is our tsvfilename\n",
    "# Make sure it is a valid filename that ends in .tsv\n",
    "testtsv = \"Your filename here.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cc89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tree from our trainingset\n",
    "create_tree_train_set(trainingloaded[\"tags\"], testtsv, path_to_server_dir)\n",
    "# Before running the rest of the cells, this tree file needs to be moved to the folder of the recommenderserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell can take a while to run\n",
    "\n",
    "# Creating a multiquery from our test questions set\n",
    "questions_multi = [json.dumps(q) for q in questions]\n",
    "\n",
    "full_results = []\n",
    "\n",
    "# Querying the server in batches of 100\n",
    "for i in range(0, len(questions_multi), 100):\n",
    "    # A quick way to keep an eye on your progress while running\n",
    "    print(i, i+100)\n",
    "    batch_results = multiquery(testtsv, path_to_server_dir, questions_multi[i:i+100])\n",
    "    full_results.append(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly compile all batches into one\n",
    "all_results = []\n",
    "\n",
    "for i in full_results:\n",
    "    all_results += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a154b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True if you want to save your results\n",
    "if False:\n",
    "    with open('predicted_answers_schematree_test', 'wb') as fb:\n",
    "        pickle.dump(full_results, fb)\n",
    "\n",
    "# Otherwise you can load previous results to check the classification report\n",
    "with open('predicted_answers_schematree_test', 'rb') as fb:\n",
    "    full_results = pickle.load(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(answers, all_results, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28944d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code utilizes convert_report2excel to put the classifaction report into excel for easier lookup\n",
    "\n",
    "workbook = Workbook()\n",
    "workbook.remove(workbook.active) # Delete default sheet.\n",
    "\n",
    "report = classification_report(\n",
    "    answers,\n",
    "    all_results[:8291],\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "workbook = convert_report2excel(\n",
    "    workbook=workbook,\n",
    "    report=report,\n",
    "    sheet_name = \"schematree2_report\"\n",
    ")\n",
    "workbook.save(\"schematree2_report.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
