{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a01d785a",
   "metadata": {},
   "source": [
    "*Openstreetmap new tag recommendations*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f89e0",
   "metadata": {},
   "source": [
    "possible improvements:    \n",
    "-   use library pyrosm (https://pyrosm.readthedocs.io/en/latest/)    \n",
    "-   write the results of queries into a file (results.json or smth) instead of just printing      \n",
    "-   create a function that takes lines from the tsv file and deletes tags for use of evaluation     \n",
    "-   create a function that takes as input an evaluation set (list of lists of strings) and just runs all the queries together    \n",
    "\n",
    "Ideas for RQ or topics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "66be8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmium\n",
    "import csv\n",
    "import subprocess\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378d8f5",
   "metadata": {},
   "source": [
    "The function convert_tsv takes the path to a .osm.pbf file with geodata and will convert it into a tsv file (called filename) usable for the recommenderserver.\n",
    "It uses osmium to open it, then takes all the points with tags and adds the tags in a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d9f6d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tsv(path: str, filename: str):\n",
    "    \"\"\"\n",
    "    Converts a .osm.pbf file with geodata from osm to a tsv file usable for RecommenderServer\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as tsvfile:\n",
    "        tsv_writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "        \n",
    "\n",
    "        for obj in osmium.FileProcessor(path):\n",
    "            if len(obj.tags) > 0:\n",
    "                object = []\n",
    "                for i in obj.tags:\n",
    "                    i = str(i).split(\"=\")\n",
    "                    object.append(i[0])\n",
    "                tsv_writer.writerow(object)\n",
    "        \n",
    "        tsvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16d9b1",
   "metadata": {},
   "source": [
    "The function create_tree calls convert_tsv to create a tsv, then runs the recommenderserver build-tree command to build a tree from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1608bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(path_to_source_file: str, tsvfilename: str, path_to_server_dir: str):\n",
    "    \"\"\"\n",
    "    Calls convert_tsv and and then creates a tree with it\n",
    "    \"\"\"\n",
    "    convert_tsv(path_to_source_file, tsvfilename)\n",
    "    result = subprocess.run(['cmd', '/c', 'cd'], capture_output=True, text=True)\n",
    "    subprocess.run(['RecommenderServer', 'build-tree', 'from-tsv', result.stdout.strip() + '/' + tsvfilename], cwd= path_to_server_dir)\n",
    "\n",
    "def create_tree_train_set(training_set:dict, tsvfilename:str, path_to_server_dir: str):\n",
    "    \"\"\"\n",
    "    Converts to tsv and creates a tree\n",
    "    Takes as input a pois[\"tags\"] column of a pandas geodata object\n",
    "    Meant for use in final experiments\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(tsvfilename, \"w\") as tsvfile:\n",
    "        tsv_writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "        for obj in training_set:\n",
    "            listed = list(obj.keys())\n",
    "            if len(listed) > 0:\n",
    "                tsv_writer.writerow(listed)\n",
    "        \n",
    "        tsvfile.close()\n",
    "    result = subprocess.run(['cmd', '/c', 'cd'], capture_output=True, text=True)\n",
    "    subprocess.run(['RecommenderServer', 'build-tree', 'from-tsv', result.stdout.strip() + '/' + tsvfilename], cwd= path_to_server_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f00d393",
   "metadata": {},
   "source": [
    "The query function will query a recommender tree that was already created from file filename, and in the recommenderserver directory path_to_server_dir. It will query a list of properties, and print the n most probable recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2f68a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(tsvfilename: str, path_to_server_dir: str, property_list: list[str], n:int = 1):\n",
    "    \"\"\"\n",
    "    Opens a recommenderserver and queries it with a property list. \n",
    "    n: number of recommendations to print\n",
    "    \"\"\"\n",
    "    open_server = subprocess.Popen(['RecommenderServer', 'serve', tsvfilename + '.schemaTree.typed.pb'], cwd= path_to_server_dir)\n",
    "    time.sleep(1)\n",
    "    powershell_command = \"\"\"\n",
    "    $body = '{\"properties\": \"\"\" + property_list + \"\"\",\"types\":[]}'\n",
    "    $response = Invoke-WebRequest -Uri \"http://localhost:8080/recommender\" -Method POST -Body $body -ContentType \"application/json\"\n",
    "    $response.Content\n",
    "    \"\"\"\n",
    "    result = subprocess.run([\"powershell\", \"-Command\", powershell_command], capture_output=True, text=True)\n",
    "        \n",
    "    output_string = result.stdout\n",
    "    recommendations_list = output_string.split(\"{\")\n",
    "    for i in recommendations_list[2:n+2]:\n",
    "        # A possible improvement is to not print, but store it (perhaps write it in a file)\n",
    "        print(i)\n",
    "    \n",
    "    open_server.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6e5a57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiquery(tsvfilename: str, path_to_server_dir: str, query_list: list[list[str]], n:int = 1) -> list[str]:\n",
    "    \"\"\"\n",
    "    Opens a server and queries it multiple times without closing the server\n",
    "    Stores the query results in order\n",
    "    This function in its current form only works for n = 1 (if it only takes the first and most likely response)\n",
    "    \"\"\"\n",
    "\n",
    "    open_server = subprocess.Popen(['RecommenderServer', 'serve', tsvfilename + '.schemaTree.typed.pb'], cwd= path_to_server_dir)\n",
    "    response_list = []\n",
    "\n",
    "    for property_list in query_list:\n",
    "        \n",
    "        #time.sleep(.5)\n",
    "        powershell_command = \"\"\"\n",
    "        $body = '{\"properties\": \"\"\" + property_list + \"\"\",\"types\":[]}'\n",
    "        $response = Invoke-WebRequest -Uri \"http://localhost:8080/recommender\" -Method POST -Body $body -ContentType \"application/json\"\n",
    "        $response.Content\n",
    "        \"\"\"\n",
    "        result = subprocess.run([\"powershell\", \"-Command\", powershell_command], capture_output=True, text=True)\n",
    "        \n",
    "        parsed = json.loads(result.stdout)\n",
    "        for rec in parsed[\"recommendations\"][:n]:\n",
    "            if rec[\"property\"] is None:\n",
    "                response_list.append(\"None\")\n",
    "                print(\"None\")\n",
    "            else: \n",
    "                response_list.append(rec[\"property\"])\n",
    "                #print(rec['property'])\n",
    "        # output_string = result.stdout\n",
    "        # recommendations_list = output_string.split(\":\")\n",
    "        # print(output_string)\n",
    "        # for i in recommendations_list[2:n+2]:\n",
    "        #     print(\"Querying\", i)\n",
    "        #     response_list.append(i)\n",
    "        \n",
    "    open_server.terminate()\n",
    "    \n",
    "    return response_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcff409",
   "metadata": {},
   "source": [
    "Testing the code and running early experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4cd2aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change for use:\n",
    "\n",
    "# Path to a geodata file (.osm.pbf format)\n",
    "path_to_source_file = 'C:/Users/jotan/Downloads/groningen-latest.osm.pbf'    \n",
    "# What to call your file (and your tree)\n",
    "tsvfilename = \"groningen.tsv\"\n",
    "# Path to the RecommenderServer folder\n",
    "path_to_server_dir = 'C:/Users/jotan/SchoolStuffs/2024-25/BachelorProject/RecommenderServer'\n",
    "\n",
    "# For querying: must be a stringed lists of strings\n",
    "example_q1 = '[\"name\", \"traffic sign\", \"type\"]'\n",
    "example_q2 = '[\"type\"]'\n",
    "example_q3 = '[\"brand\",\t\"brand:wikidata\", \"brand:wikipedia\", \"operator:wikidata\"]'\n",
    "\n",
    "multi_q1 = [example_q1, example_q2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c8131c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tree(path_to_source_file, tsvfilename, path_to_server_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1b96fd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"property\":\"name\",\"probability\":1},\n",
      "\"property\":\"operator\",\"probability\":1},\n",
      "\"property\":\"amenity\",\"probability\":0.5616438356164384},\n",
      "\"property\":\"network\",\"probability\":0.5068493150684932},\n",
      "\"property\":\"network:wikidata\",\"probability\":0.4931506849315068},\n"
     ]
    }
   ],
   "source": [
    "query(tsvfilename, path_to_server_dir, example_q3, 5)\n",
    "# query(tsvfilename, path_to_server_dir, example_q2, 5)\n",
    "\n",
    "# responses = multiquery(tsvfilename, path_to_server_dir, multi_q1, 1)\n",
    "# print(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b2f33f",
   "metadata": {},
   "source": [
    "Running the experimetns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5af98922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the training set to create the tree\n",
    "with open('trainingset', 'rb') as fp:\n",
    "    trainingloaded = pickle.load(fp)\n",
    "# And the test set for querying and answers for checking\n",
    "with open('testset_questions', 'rb') as fp:\n",
    "    questions = pickle.load(fp)\n",
    "with open('testset_answer', 'rb') as fp:\n",
    "    answers = pickle.load(fp)\n",
    "\n",
    "newtsvfilename = \"amsterdam.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f38b5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tree_train_set(trainingloaded[\"tags\"], newtsvfilename, path_to_server_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "923fafe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"property\":\"operator\",\"probability\":1},\n",
      "\"property\":\"name\",\"probability\":1},\n",
      "\"property\":\"amenity\",\"probability\":0.5616438356164384},\n",
      "\"property\":\"network\",\"probability\":0.5068493150684932},\n",
      "\"property\":\"network:wikidata\",\"probability\":0.4931506849315068},\n"
     ]
    }
   ],
   "source": [
    "# Send a single query to check if the tree works\n",
    "query(newtsvfilename, path_to_server_dir, example_q3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b039e17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8291"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a multiquery from our test questions set\n",
    "questions_multi = [json.dumps(q) for q in questions]\n",
    "len(questions_multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2279c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100\n",
      "100 200\n",
      "200 300\n",
      "300 400\n",
      "400 500\n",
      "500 600\n",
      "600 700\n",
      "700 800\n",
      "800 900\n",
      "900 1000\n",
      "1000 1100\n",
      "1100 1200\n",
      "1200 1300\n",
      "1300 1400\n",
      "1400 1500\n",
      "1500 1600\n",
      "1600 1700\n",
      "1700 1800\n",
      "1800 1900\n",
      "1900 2000\n",
      "2000 2100\n",
      "2100 2200\n",
      "2200 2300\n",
      "2300 2400\n",
      "2400 2500\n",
      "2500 2600\n",
      "2600 2700\n",
      "2700 2800\n",
      "2800 2900\n",
      "2900 3000\n",
      "3000 3100\n",
      "3100 3200\n",
      "3200 3300\n",
      "3300 3400\n",
      "3400 3500\n",
      "3500 3600\n",
      "3600 3700\n",
      "3700 3800\n",
      "3800 3900\n",
      "3900 4000\n",
      "4000 4100\n",
      "4100 4200\n",
      "4200 4300\n",
      "4300 4400\n",
      "4400 4500\n",
      "4500 4600\n",
      "4600 4700\n",
      "4700 4800\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 1 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(questions_multi), \u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     batch_results \u001b[38;5;241m=\u001b[39m multiquery(newtsvfilename, path_to_server_dir, questions_multi[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m100\u001b[39m])\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#break\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     full_results\u001b[38;5;241m.\u001b[39mappend(batch_results)\n",
      "Cell \u001b[1;32mIn[145], line 21\u001b[0m, in \u001b[0;36mmultiquery\u001b[1;34m(tsvfilename, path_to_server_dir, query_list, n)\u001b[0m\n\u001b[0;32m     14\u001b[0m powershell_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m$body = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m+\u001b[39m property_list \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:[]}\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m$response = Invoke-WebRequest -Uri \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:8080/recommender\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -Method POST -Body $body -ContentType \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m$response.Content\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     19\u001b[0m result \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpowershell\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-Command\u001b[39m\u001b[38;5;124m\"\u001b[39m, powershell_command], capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 21\u001b[0m parsed \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(result\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecommendations\u001b[39m\u001b[38;5;124m\"\u001b[39m][:n]:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperty\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 1)"
     ]
    }
   ],
   "source": [
    "full_results = []\n",
    "\n",
    "for i in range(0, len(questions_multi), 100):\n",
    "    print(i, i+100)\n",
    "    batch_results = multiquery(newtsvfilename, path_to_server_dir, questions_multi[i:i+100])\n",
    "    #break\n",
    "    full_results.append(batch_results)\n",
    "print(batch_results)\n",
    "print(len(batch_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('predicted_answers_schematree', 'wb') as fb:\n",
    "#     pickle.dump(full_results, fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "427de461",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for i in full_results:\n",
    "    all_results += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e70172fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4587\n",
      "8291\n",
      "98\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 access       0.00      0.00      0.00       5.0\n",
      "       addr:housenumber       0.00      0.00      0.00       0.0\n",
      "                amenity       0.00      0.00      0.00       0.0\n",
      "           artwork_type       0.00      0.00      0.00       1.0\n",
      "                bicycle       0.00      0.00      0.00       0.0\n",
      "          brand:website       0.00      0.00      0.00       1.0\n",
      "         brand:wikidata       0.00      0.00      0.00       4.0\n",
      "                    bus       0.00      0.00      0.00       0.0\n",
      "               capacity       0.00      0.00      0.00       7.0\n",
      "             check_date       0.00      0.00      0.00       2.0\n",
      "                 colour       0.00      0.00      0.00       2.0\n",
      "                covered       0.00      0.00      0.00       1.0\n",
      "                cuisine       0.00      0.00      0.00       1.0\n",
      "            description       0.00      0.00      0.00       1.0\n",
      "                    fee       0.00      0.00      0.00       5.0\n",
      "                highway       0.00      0.00      0.00       0.0\n",
      "               location       0.00      0.00      0.00       2.0\n",
      "               map_type       0.00      0.00      0.00       1.0\n",
      "               material       0.00      0.00      0.00       3.0\n",
      "               maxspeed       0.00      0.00      0.00       0.0\n",
      "                   name       0.00      0.00      0.00       0.0\n",
      "          opening_hours       0.00      0.00      0.00       0.0\n",
      "               operator       0.00      0.00      0.00       0.0\n",
      "      operator:wikidata       0.00      0.00      0.00       3.0\n",
      "     operator:wikipedia       0.00      0.00      0.00       0.0\n",
      "            orientation       0.00      0.00      0.00      10.0\n",
      "        outdoor_seating       0.00      0.00      0.00       1.0\n",
      "                parking       0.00      0.00      0.00       0.0\n",
      "          parking_space       0.00      0.00      0.00       9.0\n",
      "    payment:contactless       0.00      0.00      0.00       1.0\n",
      "               phone:NL       0.00      0.00      0.00       1.0\n",
      "      recycling:cartons       0.00      0.00      0.00       0.0\n",
      "        recycling:glass       0.00      0.00      0.00       1.0\n",
      "recycling:glass_bottles       0.00      0.00      0.00       1.0\n",
      "         recycling_type       0.00      0.00      0.00       2.0\n",
      "           ref:rustpunt       0.00      0.00      0.00       1.0\n",
      "               religion       0.00      0.00      0.00       0.0\n",
      "                  seats       0.00      0.00      0.00       1.0\n",
      "                   shop       0.00      0.00      0.00       0.0\n",
      "             smoothness       0.00      0.00      0.00       9.0\n",
      "           socket:type2       0.00      0.00      0.00       1.0\n",
      "                 source       0.00      0.00      0.00       0.0\n",
      "            source:date       0.00      0.00      0.00       3.0\n",
      "             start_date       0.00      0.00      0.00       0.0\n",
      "                surface       0.00      0.00      0.00      12.0\n",
      "            survey:date       0.00      0.00      0.00       1.0\n",
      "               takeaway       0.00      0.00      0.00       0.0\n",
      "                tourism       0.00      0.00      0.00       0.0\n",
      "                website       0.00      0.00      0.00       0.0\n",
      "             wheelchair       0.00      0.00      0.00       2.0\n",
      "      wikimedia_commons       0.00      0.00      0.00       2.0\n",
      "\n",
      "               accuracy                           0.00      97.0\n",
      "              macro avg       0.00      0.00      0.00      97.0\n",
      "           weighted avg       0.00      0.00      0.00      97.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(len(all_results))\n",
    "print(len(answers))\n",
    "print(len(batch_results))\n",
    "print(classification_report(answers[:97], batch_results[:97]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb273b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recycling:glass\n",
      "\"property\":\"amenity\",\"probability\":1},\n",
      "\"property\":\"recycling:paper\",\"probability\":0.35},\n",
      "\"property\":\"opening_hours\",\"probability\":0.2},\n",
      "\"property\":\"recycling:clothes\",\"probability\":0.15833333333333333},\n",
      "\"property\":\"check_date:recycling\",\"probability\":0.11666666666666667},\n"
     ]
    }
   ],
   "source": [
    "print(answers[0])\n",
    "query(newtsvfilename, path_to_server_dir, json.dumps(questions[0]), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in full_results:\n",
    "    for j in range(len(i)):\n",
    "        print(i[j], answers[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
