{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "459c13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c661621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrosm.data import sources\n",
    "import pyrosm\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "209efeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse tags\n",
    "\n",
    "def parse_tags(val):\n",
    "    if pd.isna(val) or val in [\"None\", \"nan\", None]:\n",
    "        return {}\n",
    "    try:\n",
    "        return ast.literal_eval(val) if isinstance(val, str) else val\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "#pois[\"tags\"] = pois[\"tags\"].apply(parse_tags) #only need to run it once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1decb6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_lists(pois, n):\n",
    "    tag_freq = defaultdict(int)\n",
    "    #print(tag_freq)\n",
    "\n",
    "\n",
    "\n",
    "    for idx, row in pois.iterrows(): \n",
    "        tags = row.get(\"tags\", {})\n",
    "        #print(f\"Row {idx}, Tags: {tags}, Type: {type(tags)}\")  # Check type of tags\n",
    "\n",
    "        if isinstance(tags, dict) and tags:\n",
    "            for tag_key in tags:\n",
    "                tag_freq[tag_key] += 1\n",
    "\n",
    "\n",
    "    # print(tag_freq)\n",
    "    all_tags = list(tag_freq.keys())\n",
    "    all_good_tags = [tag for tag in tag_freq if tag_freq[tag] > n]\n",
    "    tag2idx = {tag: i for i, tag in enumerate(all_good_tags)}\n",
    "    idx2tag = {i: tag for tag, i in tag2idx.items()}\n",
    "\n",
    "    tag_freq = dict(sorted(tag_freq.items(), key = lambda x: x[1], reverse = True))\n",
    "    print(f\"All tags sorted by frequency: {tag_freq}\")\n",
    "    print(f\" All allowed tags: {all_good_tags}\")\n",
    "    # print(tag2idx)\n",
    "    # print(idx2tag)\n",
    "    print(f\"Len all tags: {len(all_tags)}, Len good tags: {len(all_good_tags)}\")\n",
    "    #print(\"\\n Returning (all_good_tags, tag2idx)\")\n",
    "\n",
    "\n",
    "    return (all_good_tags, tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "31cc3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_tags(good_tags, pois):\n",
    "    for i in pois[\"tags\"]:\n",
    "        remove_list = []\n",
    "        for j in i:\n",
    "            if j not in good_tags:\n",
    "                remove_list.append(j)\n",
    "        for removable in remove_list:\n",
    "            #print(f\"removing {removable} from {i}\")\n",
    "            i.pop(removable)\n",
    "            #print(f\"after remnoval: {i}\")     \n",
    "\n",
    "def remove_bad_tags_test(good_tags, poisX, poisy):\n",
    "    for i in poisX:\n",
    "        remove_list = []\n",
    "        for j in i:\n",
    "            if j not in good_tags:\n",
    "                remove_list.append(j)\n",
    "        for removable in remove_list:\n",
    "            #print(f\"removing {removable} from {i}\")\n",
    "            print(i, removable)\n",
    "            i.remove(removable)\n",
    "            #print(f\"after remnoval: {i}\")\n",
    "    for i in poisy:\n",
    "        remove_list = []\n",
    "        for j in i:\n",
    "            if j not in good_tags:\n",
    "                remove_list.append(j)\n",
    "        for removable in remove_list:\n",
    "            #print(f\"removing {removable} from {i}\")\n",
    "            i.remove(removable)\n",
    "            #print(f\"after remnoval: {i}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "452e3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_vec(tag_dict, tag2idx):\n",
    "    vector = np.zeros(len(tag2idx), dtype= np.float32)\n",
    "    if isinstance(tag_dict, dict):\n",
    "        for tag in tag_dict:\n",
    "            if tag in tag2idx:\n",
    "                vector[tag2idx[tag]] = 1\n",
    "    return vector\n",
    "\n",
    "def tags_to_vec_singular(solo_tag, tag2idx):\n",
    "    vector = np.zeros(len(tag2idx), dtype= np.float32)\n",
    "    #if isinstance(tag_dict, dict):\n",
    "    if solo_tag in tag2idx:\n",
    "        vector[tag2idx[solo_tag]] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "83983358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_pois(pois, tag2idx, n):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for tag in pois[\"tags\"]:\n",
    "        if not isinstance(tag, dict) or len(tag) < n: # set the len to 1 will include empty {}\n",
    "            continue\n",
    "\n",
    "        tag_keys = list(tag.keys())\n",
    "\n",
    "        np.random.shuffle(tag_keys)\n",
    "        \n",
    "        mid_idx = len(tag_keys) // 2\n",
    "        #print(mid_idx)\n",
    "        input_tags = {k: tag[k] for k in tag_keys[:mid_idx]}\n",
    "        output_tags = {k: tag[k] for k in tag_keys[mid_idx:]}\n",
    "\n",
    "        # print(\"input_tags\", input_tags)\n",
    "        # print(\"   \")\n",
    "        # print(\"output_tags\", output_tags)\n",
    "        # print(\"--------------------------------\")\n",
    "        #vec = tags_to_vec(input_tags, tag2idx)\n",
    "        #print(\"vector\",vec) #tag to vector testing\n",
    "\n",
    "\n",
    "        X.append(tags_to_vec(input_tags, tag2idx))\n",
    "        y.append(tags_to_vec(output_tags, tag2idx))\n",
    "\n",
    "    X = np.stack(X)\n",
    "    #print(X)\n",
    "    y = np.stack(y)\n",
    "    print(\"X shape:\", X.shape)\n",
    "\n",
    "    print(\"y_shape\", y.shape)\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def vector_pois_opt(pois, tag2idx, n):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for tag in pois[\"tags\"]:\n",
    "        if not isinstance(tag, dict) or len(tag) < n: # set the len to 1 will include empty {}\n",
    "            continue\n",
    "\n",
    "        tag_keys = list(tag.keys())\n",
    "\n",
    "        np.random.shuffle(tag_keys)\n",
    "        \n",
    "        for feature_idx in range(len(tag)//2):\n",
    "            input_tags = {k: tag[k] for k in tag_keys[:feature_idx] + tag_keys[feature_idx + 1:]}\n",
    "            output_tags = {tag_keys[feature_idx] : tag[tag_keys[feature_idx]]}\n",
    "\n",
    "\n",
    "            X.append(tags_to_vec(input_tags, tag2idx))\n",
    "            y.append(tags_to_vec(output_tags, tag2idx))\n",
    "    \n",
    "    X = np.stack(X)\n",
    "    #print(X)\n",
    "    y = np.stack(y)\n",
    "    print(\"X shape:\", X.shape)\n",
    "\n",
    "    print(\"y_shape\", y.shape)\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def vector_pois_test(poisX, poisy, tag2idx, n):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for tag in poisX:\n",
    "        if len(tag) < n: # set the len to 1 will include empty {}\n",
    "            print(tag)\n",
    "            continue\n",
    "        X.append(tags_to_vec(tag, tag2idx))\n",
    "    for tag in poisy:\n",
    "        y.append(tags_to_vec_singular(tag, tag2idx))\n",
    "\n",
    "    \n",
    "    X = np.stack(X)\n",
    "    y = np.stack(y)\n",
    "    print(\"X_shape:\", X.shape)\n",
    "\n",
    "    print(\"y_shape\", y.shape)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b6147551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = pyrosm.get_data(\"Amsterdam\")\n",
    "# osm = pyrosm.OSM(fp)\n",
    "# pois = osm.get_pois()\n",
    "# pois[\"tags\"] = pois[\"tags\"].apply(parse_tags) #only need to run it once\n",
    "\n",
    "with open('trainingset', 'rb') as fp:\n",
    "    pois = pickle.load(fp)\n",
    "with open('testset_questions', 'rb') as fp:\n",
    "    test_pois_X = pickle.load(fp)\n",
    "with open('testset_answer', 'rb') as fp:\n",
    "    test_pois_y = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b8976587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tags sorted by frequency: {'surface': 17633, 'smoothness': 11035, 'parking_space': 10687, 'access': 8889, 'capacity': 8692, 'fee': 7354, 'orientation': 6272, 'source:date': 5013, 'wheelchair': 3692, 'brand': 3571, 'brand:wikidata': 3456, 'lit': 2499, 'maxstay:conditional': 2375, 'check_date': 2178, 'material': 1939, 'operator:wikidata': 1917, 'brand:wikipedia': 1726, 'cuisine': 1554, 'backrest': 1403, 'recycling_type': 1334, 'colour': 1034, 'covered': 955, 'ref:bag': 933, 'seats': 865, 'outdoor_seating': 853, 'brand:website': 850, 'wikidata': 781, 'takeaway': 685, 'operator:wikipedia': 665, 'recycling:paper': 664, 'artwork_type': 639, 'wikimedia_commons': 557, 'level': 552, 'artist_name': 539, 'recycling:glass_bottles': 508, 'branch': 501, 'description': 499, 'layer': 484, 'indoor_seating': 476, 'note': 446, 'socket:type2': 434, 'payment:cash': 434, 'toilets:wheelchair': 408, 'contact:facebook': 398, 'denomination': 362, 'capacity:disabled': 361, 'contact:instagram': 348, 'min_age': 340, 'diet:vegetarian': 336, 'recycling:waste': 336, 'location': 333, 'max_age': 325, 'waste': 319, 'alt_name': 319, 'recycling:cardboard': 301, 'payment:credit_cards': 298, 'internet_access:fee': 297, 'bottle': 290, 'motorcar': 288, 'recycling:plastic': 269, 'name:nl': 254, 'operator:website': 253, 'payment:debit_cards': 244, 'payment:contactless': 243, 'delivery': 242, 'drive_through': 234, 'smoking': 233, 'recycling:glass': 232, 'isced': 229, 'recycling:newspaper': 219, 'recycling:paper_packaging': 218, 'payment:maestro': 216, 'recycling:cans': 215, 'indoor': 213, 'recycling:magazines': 212, 'vending': 210, 'diet:vegan': 208, 'healthcare': 207, 'operator:type': 202, 'name:en': 197, 'recycling:plastic_packaging': 196, 'mapillary': 195, 'recycling:clothes': 192, 'survey:date': 189, 'socket:type2:output': 189, 'man_made': 179, 'maxstay': 178, 'payment:coins': 177, 'direction': 175, 'payment:mastercard': 173, 'supervised': 173, 'image': 171, 'recycling:plastic_bottles': 170, 'payment:visa': 170, 'old_name': 167, 'toilets': 152, 'self_service': 151, 'currency:EUR': 148, 'check_date:opening_hours': 146, 'park_ride': 144, 'recycling:green_waste': 141, 'recycling:books': 134, 'isced:level': 133, 'amperage': 130, 'voltage': 130, 'shelter_type': 130, 'collection_times': 129, 'official_name': 127, 'surface:colour': 122, 'hiking': 121, 'male': 110, 'armrest': 107, 'capacity:charging': 107, 'phone:NL': 107, 'recycling:batteries': 106, 'bench': 105, 'support': 101, 'bin': 100, 'display': 98, 'pedagogy': 98, 'beds': 97, 'female': 95, 'recycling:small_appliances': 94, 'recycling:electrical_appliances': 92, 'pets_allowed': 91, 'charge': 87, 'contact:website': 83, 'fuel:diesel': 82, 'network': 81, 'stars': 81, 'contact:phone': 79, 'recycling:beverage_cartons': 79, 'maxheight': 79, 'changing_table': 78, 'visibility': 74, 'heritage': 71, 'map_size': 69, 'paving_stones:length': 69, 'map_type': 68, 'historic': 68, 'area': 68, 'type': 68, 'paving_stones:shape': 68, 'website:menu': 65, 'fuel:octane_95': 65, 'air_conditioning': 65, 'healthcare:speciality': 65, 'service:bicycle:repair': 65, 'heritage:operator': 64, 'faces': 64, 'panoramax': 64, 'reservation': 64, 'authentication:nfc': 64, 'recycling:cartons': 63, 'opening_hours:signed': 62, 'highway': 62, 'cash_in': 60, 'fixme': 60, 'authentication:membership_card': 59, 'date': 58, 'contact:email': 57, 'authentication:app': 56, 'authentication:contactless': 56, 'artwork_subject': 55, 'payment:electronic_purses': 54, 'recycling:wood': 54, 'socket:type2_cable': 54, 'inscription': 53, 'fax': 53, 'payment:app': 53, 'operator:short': 53, 'socket:type2_cable:output': 52, 'payment:cards': 51, 'paving_stones:width': 50, 'diet:halal': 50, 'recycling:shoes': 50, 'short_name': 49, 'rooms': 49, 'service:bicycle:retail': 48, 'compressed_air': 46, 'note:url': 46, 'artist:wikidata': 46, 'atmotorway': 44, 'payment:notes': 44, 'currency:XBT': 43, 'name:ru': 43, 'toilets:disposal': 42, 'contact:twitter': 42, 'height': 42, 'payment:onchain': 41, 'public_transport': 41, 'airside': 40, 'ref:rce': 40, 'fuel:octane_98': 39, 'payment:pin': 39, 'dispensing': 39, 'osmc:symbol': 38, 'symbol:nl': 38, 'waycolor': 38, 'name:de': 38, 'toilets:position': 37, 'service:bicycle:pump': 37, 'payment:american_express': 36, 'post:city': 36, 'post:housenumber': 36, 'post:postcode': 36, 'post:street': 36, 'ref:gers': 35, 'sport': 35, 'social_facility:for': 35, 'barrier': 35, 'thermometer': 34, 'check_date:recycling': 34, 'hgv': 34, 'barometer': 33, 'hygrometer': 33, 'leisure': 33, 'payment:lightning': 33, 'payment:lightning_contactless': 33, 'recycling:pmd': 33, 'politie:eenheid': 33, 'addr:floor': 32, 'noname': 32, 'fee:conditional': 32, 'politie:basisteam': 32, 'politie:district': 32, 'memorial': 32, 'service:vehicle:car_repair': 31, 'automated': 31, 'recycling:scrap_metal': 30, 'seasonal': 30, 'bus': 29, 'building:part': 29, 'emergency': 29, 'bic': 29, 'moped': 29, 'ferry': 29, 'recycling:glass_bottles:colour': 28, 'designation': 28, 'name:zh': 28, 'foot': 28, 'service:bicycle:rental': 27, 'mofa': 27, 'unisex': 26, 'facebook': 26, 'authentication:none': 26, 'service:bicycle:second_hand': 26, 'roof:shape': 26, 'diet:gluten_free': 26, 'brewery': 25, 'name:es': 25, 'wheelchair:description': 24, 'not:brand:wikidata': 24, 'socket:type2_combo': 24, 'socket:type2_combo:output': 24, 'guide_type': 23, 'artist:wikipedia': 23, 'beauty': 23, 'internet_access:ssid': 23, 'motor_vehicle': 23, 'club': 22, 'caravans': 22, 'architect': 22, 'fuel:e10': 22, 'lgbtq': 22, 'tents': 21, 'payment:v_pay': 21, 'community_centre': 21, 'toilets:access': 21, 'service:vehicle:inspection': 21, 'shower': 20, 'service:vehicle:used_car_sales': 20, 'name:ko': 20, 'payment:cryptocurrencies': 20, 'fuel:lpg': 20, 'food': 20, 'public_bookcase:type': 20, 'drink:beer': 20, 'name:uk': 20, 'parking:fee': 19, 'contact:whatsapp': 19, 'service:vehicle:tyres': 19, 'name:fa': 19, 'toilets:menstrual_products': 19, 'source:geometry': 18, 'tourist_bus': 18, 'count': 18, 'recycling:organic': 17, 'payment:apple_pay': 17, 'diet:kosher': 17, 'service:vehicle:diagnostics': 17, 'diet:meat': 17, 'operator:abbr': 17, 'roof:levels': 16, 'service:vehicle:air_conditioning': 16, 'description:en': 16, 'ref:EU:EVSE': 16, 'mobile': 16, 'payment:dkv': 15, 'board_type': 15, 'contact:linkedin': 15, 'int_name': 15, 'shelter': 15, 'microbrewery': 15, 'service_times': 15, 'guidepost': 14, 'size': 14, 'recycling:garden_waste': 14, 'full_name': 14, 'lamp_mount': 14, 'lamp_type': 14, 'payment:account_cards': 14, 'building:levels:underground': 14, 'payment:travelcard': 14, 'network:wikidata': 14, 'recycling:textiles': 14, 'emergency_telephone_code': 14, 'power_supply': 13, 'cash_out': 13, 'ele': 13, 'service:vehicle:brakes': 13, 'service:vehicle:glass': 13, 'payment:multitankcard': 13, 'payment:vpay': 13, 'laundry_service': 13, 'scooter': 13, 'ref:rustpunt': 13, 'name:fr': 13, 'payment:google_pay': 13, 'service:vehicle:batteries': 12, 'service:vehicle:car_parts': 12, 'service:vehicle:oil_change': 12, 'service:bicycle:parts': 12, 'payment:q8_liberty': 12, 'payment:xximo': 12, 'disabled': 12, 'check_date:capacity': 12, 'building:material': 12, 'service': 12, 'tactile_paving': 12, 'name:it': 12, 'traffic_sign': 11, 'recycling:metal_packaging': 11, 'check_date:currency:XBT': 11, 'socket:chademo': 11, 'stroller': 11, 'owner': 11, 'horse': 11, 'phone:business': 11, 'capacity:car_sharing': 11, 'service:vehicle:maintenance': 11, 'fuel:cng': 11, 'fuel:GTL_diesel': 11, 'toilets:handwashing': 10, 'opening_hours:kitchen': 10, 'socket:chademo:output': 10, 'payment:ipay': 10, 'fuel:adblue': 10, 'dog': 10, 'highchair': 10, 'year': 10, 'parking:maxstay:conditional': 9, 'website:map': 9, 'roof:material': 9, 'oneway': 9, 'opening_hours:url': 9, 'truck': 9, 'atmotorroad': 9, 'service:bicycle:ebike': 9, 'female:signed': 9, 'male:signed': 9, 'bench:direction': 8, 'underground': 8, 'sanitary_dump_station': 8, 'entrance': 8, 'ref:isil': 8, 'vehicle': 8, 'created_by': 8, 'subject:wikidata': 7, 'contact:mobile': 7, 'addr:unit': 7, 'polling_station': 7, 'access:conditional': 7, 'description:nl': 7, 'origin': 7, 'phone:mobile': 7, 'ref:vatin': 7, 'payment:ov-chipkaart': 6, 'cargo_bike': 6, 'waterway': 6, 'parking:restriction': 6, 'natural': 6, 'rental': 6, 'studio': 5, 'source:geometry:date': 4, 'parcel_pickup': 4, 'ref:kvk': 3, 'produce': 3, 'seamark:bridge:category': 3, 'trolley:deposit': 2}\n",
      " All allowed tags: ['fee', 'parking_space', 'smoothness', 'surface', 'branch', 'brand', 'brand:website', 'brand:wikidata', 'source:date', 'access', 'capacity', 'orientation', 'heritage', 'heritage:operator', 'name:en', 'name:nl', 'wikidata', 'wikimedia_commons', 'wheelchair', 'lit', 'maxstay:conditional', 'brand:wikipedia', 'cash_in', 'check_date', 'indoor', 'operator:wikidata', 'operator:wikipedia', 'beds', 'ref:bag', 'contact:phone', 'cuisine', 'description', 'diet:vegan', 'diet:vegetarian', 'drive_through', 'indoor_seating', 'internet_access:fee', 'outdoor_seating', 'takeaway', 'contact:instagram', 'backrest', 'material', 'seats', 'colour', 'waste', 'pets_allowed', 'capacity:disabled', 'guide_type', 'guidepost', 'traffic_sign', 'covered', 'mapillary', 'survey:date', 'recycling:cartons', 'recycling:glass_bottles', 'recycling:paper', 'recycling:plastic', 'recycling:plastic_bottles', 'recycling:plastic_packaging', 'recycling_type', 'barometer', 'date', 'display', 'faces', 'hygrometer', 'panoramax', 'support', 'thermometer', 'visibility', 'operator:type', 'check_date:opening_hours', 'recycling:glass', 'club', 'leisure', 'armrest', 'direction', 'level', 'toilets:wheelchair', 'toilets', 'recycling:waste', 'size', 'hiking', 'map_size', 'map_type', 'alt_name', 'caravans', 'shower', 'tents', 'layer', 'motorcar', 'authentication:app', 'authentication:contactless', 'network', 'parking:fee', 'socket:type2', 'socket:type2:output', 'denomination', 'opening_hours:signed', 'payment:cash', 'payment:contactless', 'payment:maestro', 'payment:mastercard', 'payment:v_pay', 'payment:visa', 'recycling:beverage_cartons', 'recycling:metal_packaging', 'artist:wikipedia', 'artist_name', 'artwork_type', 'image', 'amperage', 'voltage', 'payment:credit_cards', 'payment:debit_cards', 'isced', 'max_age', 'min_age', 'isced:level', 'official_name', 'operator:website', 'payment:coins', 'payment:electronic_purses', 'vending', 'self_service', 'recycling:garden_waste', 'recycling:green_waste', 'recycling:organic', 'maxstay', 'currency:EUR', 'roof:levels', 'healthcare', 'currency:XBT', 'payment:lightning', 'payment:lightning_contactless', 'payment:onchain', 'contact:email', 'contact:website', 'contact:whatsapp', 'recycling:cardboard', 'capacity:charging', 'brewery', 'delivery', 'reservation', 'smoking', 'historic', 'old_name', 'man_made', 'payment:apple_pay', 'payment:cards', 'inscription', 'recycling:glass_bottles:colour', 'contact:facebook', 'website:menu', 'short_name', 'bottle', 'atmotorway', 'phone:NL', 'unisex', 'changing_table', 'community_centre', 'toilets:access', 'bench', 'shelter_type', 'power_supply', 'check_date:currency:XBT', 'area', 'note', 'recycling:clothes', 'facebook', 'recycling:cans', 'pedagogy', 'surface:colour', 'wheelchair:description', 'addr:floor', 'full_name', 'recycling:batteries', 'recycling:electrical_appliances', 'recycling:magazines', 'recycling:newspaper', 'recycling:paper_packaging', 'recycling:small_appliances', 'bus', 'type', 'recycling:scrap_metal', 'recycling:wood', 'paving_stones:length', 'paving_stones:shape', 'paving_stones:width', 'authentication:membership_card', 'authentication:nfc', 'location', 'recycling:pmd', 'check_date:recycling', 'recycling:books', 'toilets:disposal', 'toilets:position', 'fax', 'not:brand:wikidata', 'source:geometry', 'maxheight', 'cash_out', 'fixme', 'fuel:diesel', 'fuel:octane_95', 'fuel:octane_98', 'stars', 'ele', 'osmc:symbol', 'symbol:nl', 'waycolor', 'bin', 'supervised', 'authentication:none', 'female', 'male', 'highway', 'noname', 'beauty', 'ref:gers', 'politie:eenheid', 'lamp_mount', 'lamp_type', 'artwork_subject', 'diet:halal', 'diet:kosher', 'socket:chademo', 'socket:type2_combo', 'socket:type2_combo:output', 'air_conditioning', 'payment:american_express', 'payment:notes', 'service:vehicle:air_conditioning', 'service:vehicle:batteries', 'service:vehicle:brakes', 'service:vehicle:car_parts', 'service:vehicle:car_repair', 'service:vehicle:diagnostics', 'service:vehicle:glass', 'service:vehicle:inspection', 'service:vehicle:oil_change', 'service:vehicle:tyres', 'service:vehicle:used_car_sales', 'payment:account_cards', 'payment:pin', 'post:city', 'post:housenumber', 'post:postcode', 'post:street', 'airside', 'designation', 'dispensing', 'ref:rce', 'fee:conditional', 'sport', 'park_ride', 'hgv', 'stroller', 'compressed_air', 'architect', 'politie:basisteam', 'politie:district', 'note:url', 'charge', 'name:de', 'healthcare:speciality', 'social_facility:for', 'service:bicycle:rental', 'service:bicycle:repair', 'service:bicycle:retail', 'service:bicycle:second_hand', 'name:ko', 'name:es', 'socket:type2_cable', 'socket:type2_cable:output', 'contact:twitter', 'height', 'name:zh', 'roof:shape', 'name:fa', 'service:bicycle:parts', 'building:levels:underground', 'internet_access:ssid', 'payment:dkv', 'payment:multitankcard', 'payment:q8_liberty', 'payment:travelcard', 'payment:vpay', 'payment:xximo', 'rooms', 'diet:meat', 'collection_times', 'barrier', 'disabled', 'check_date:capacity', 'building:part', 'board_type', 'fuel:e10', 'emergency', 'tourist_bus', 'payment:app', 'network:wikidata', 'operator:short', 'laundry_service', 'payment:cryptocurrencies', 'description:en', 'toilets:menstrual_products', 'artist:wikidata', 'owner', 'operator:abbr', 'lgbtq', 'fuel:lpg', 'building:material', 'name:ru', 'contact:linkedin', 'int_name', 'food', 'seasonal', 'bic', 'horse', 'service', 'recycling:shoes', 'recycling:textiles', 'public_transport', 'shelter', 'tactile_paving', 'service:bicycle:pump', 'emergency_telephone_code', 'phone:business', 'mofa', 'moped', 'capacity:car_sharing', 'ref:EU:EVSE', 'service:vehicle:maintenance', 'public_bookcase:type', 'mobile', 'scooter', 'ferry', 'memorial', 'diet:gluten_free', 'microbrewery', 'automated', 'drink:beer', 'name:uk', 'ref:rustpunt', 'fuel:cng', 'name:it', 'foot', 'fuel:GTL_diesel', 'count', 'service_times', 'motor_vehicle', 'name:fr', 'payment:google_pay']\n",
      "Len all tags: 400, Len good tags: 353\n",
      "X shape: (12069, 353)\n",
      "y_shape (12069, 353)\n"
     ]
    }
   ],
   "source": [
    "n_good_tags = 10 # Frequency of tags for them to be allowed\n",
    "n_per_instance = 5 # Amount of tags an instance needs to have to be part of the data\n",
    "                   # If set to 1 it will include empty cells\n",
    "\n",
    "\n",
    "good_tags, tag2idx = create_tag_lists(pois, n_good_tags)\n",
    "remove_bad_tags(good_tags, pois)\n",
    "#X, Y = vector_pois_opt(pois, tag2idx, n_per_instance)\n",
    "X, Y = vector_pois(pois, tag2idx, n_per_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "65686e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape: (8291, 353)\n",
      "y_shape (8291, 353)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = vector_pois_test(test_pois_X, test_pois_y, tag2idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1498699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9595, 353)\n",
      "y_train shape: (9595, 353)\n",
      "X_test shape: (8291, 353)\n",
      "y_test shape: (8291, 353)\n",
      "X_val shape: (2474, 353)\n",
      "y_val shape: (2474, 353)\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "#X_val, _, y_val, _ = train_test_split(X, Y)\n",
    "\n",
    "X_train, y_train, X_val, y_val = iterative_train_test_split(X, Y, test_size=0.2)\n",
    "#_, _, X_val, y_val = iterative_train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "# Just checking, ive had some issues\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0d3c6e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model = False\n",
    "if check_model:\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Define search space\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "    }\n",
    "\n",
    "    # Wrap in RandomizedSearchCV\n",
    "    search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,  # Try 20 random combinations\n",
    "        cv=3,       # 3-fold cross-validation\n",
    "        scoring='f1_micro',  # Or accuracy, or a custom metric\n",
    "        n_jobs=-1,  # Use all cores\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model after search\n",
    "    best_model = search.best_estimator_\n",
    "    print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f1d8c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_model:\n",
    "    best_model = RandomForestClassifier(max_features='log2', n_estimators=300, random_state=42) # Thepreviousbestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a7b9008d",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 46268416 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    493\u001b[0m )(\n\u001b[0;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    495\u001b[0m         t,\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    497\u001b[0m         X,\n\u001b[0;32m    498\u001b[0m         y,\n\u001b[0;32m    499\u001b[0m         sample_weight,\n\u001b[0;32m    500\u001b[0m         i,\n\u001b[0;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    506\u001b[0m     )\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[0;32m    195\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[0;32m    196\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m_tree.pyx:172\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:287\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:942\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_tree.pyx:911\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_utils.pyx:35\u001b[0m, in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 46268416 bytes"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "#best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_thresholds(y_true, y_probs, thresholds=np.arange(0.1, 0.9, 0.05)):\n",
    "    best_thresholds = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        best_f1 = 0\n",
    "        best_thresh = 0.5\n",
    "        for thresh in thresholds:\n",
    "            preds = (y_probs[:, i] >= thresh).astype(int)\n",
    "            f1 = f1_score(y_true[:, i], preds, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_thresh = thresh\n",
    "        best_thresholds.append(best_thresh)\n",
    "    return np.array(best_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_probs_val = best_model.predict_proba(X_val)      \n",
    "prob_matrix_val = np.array([\n",
    "    probs[:, 1] if probs.shape[1] > 1 else np.zeros(probs.shape[0])\n",
    "    for probs in Y_probs_val]).T\n",
    "\n",
    "thresholds = find_best_thresholds(y_val, prob_matrix_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c91bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_probs_test = best_model.predict_proba(X_test)\n",
    "probs_list = []\n",
    "for probs in Y_probs_test:\n",
    "    if probs.shape[1] == 2:\n",
    "        probs_list.append(probs[:, 1])  # P(class 1)\n",
    "    else:\n",
    "        # Only class 0 was seen — so class 1 probability is 0\n",
    "        probs_list.append(np.zeros(probs.shape[0]))\n",
    "\n",
    "prob_matrix = np.array(probs_list).T\n",
    "# prob_matrix = np.array([probs[:, 1] for probs in Y_probs_test]).T\n",
    "# prob_matrix_test = np.array([\n",
    "#     probs[:, 1] if probs.shape[1] > 1 else np.zeros(probs.shape[0])\n",
    "#     for probs in Y_probs_test]).T\n",
    "\n",
    "Y_preds = (prob_matrix >= thresholds).astype(int)\n",
    "#Y_preds = (prob_matrix >= 0.01).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f640e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prob: 0.0\n",
      "Max prob: 0.2491307189542484\n",
      "Min prob: 0.1\n",
      "Max prob: 0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"Min prob:\", prob_matrix.min())\n",
    "print(\"Max prob:\", prob_matrix.max())\n",
    "\n",
    "print(\"Min prob:\", thresholds.min())\n",
    "print(\"Max prob:\", thresholds.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (8291, 353)\n",
      "y_test shape: (8291, 353)\n",
      "prob_matrix shape: (8291, 353)\n",
      "thresholds shape: (353,)\n",
      "Y_preds shape: (8291, 353)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"prob_matrix shape:\", prob_matrix.shape)\n",
    "print(\"thresholds shape:\", thresholds.shape)\n",
    "print(\"Y_preds shape:\", Y_preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae303765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labels in full dataset: 654989\n",
      "Per-tag label count: [4.21e+02 7.79e+02 8.40e+02 1.17e+03 1.30e+01 1.79e+02 3.50e+01 1.95e+02\n",
      " 2.86e+02 5.09e+02 4.88e+02 3.04e+02 3.00e+00 5.00e+00 1.00e+01 1.10e+01\n",
      " 3.30e+01 2.90e+01 1.80e+02 1.47e+02 1.15e+02 1.05e+02 3.00e+00 1.21e+02\n",
      " 6.00e+00 1.00e+02 4.10e+01 3.00e+00 5.50e+01 6.00e+00 8.30e+01 2.40e+01\n",
      " 1.10e+01 1.00e+01 7.00e+00 2.20e+01 1.50e+01 5.00e+01 3.70e+01 2.40e+01\n",
      " 9.40e+01 1.59e+02 6.90e+01 6.70e+01 1.70e+01 4.00e+00 1.70e+01 1.00e+00\n",
      " 1.00e+00 0.00e+00 7.60e+01 1.20e+01 1.50e+01 2.00e+00 3.20e+01 3.40e+01\n",
      " 1.10e+01 3.00e+00 7.00e+00 8.50e+01 1.00e+00 0.00e+00 2.00e+00 0.00e+00\n",
      " 0.00e+00 2.00e+00 4.00e+00 1.00e+00 4.00e+00 1.30e+01 3.00e+00 1.20e+01\n",
      " 0.00e+00 1.00e+00 5.00e+00 1.50e+01 2.30e+01 1.90e+01 7.00e+00 1.30e+01\n",
      " 0.00e+00 8.00e+00 3.00e+00 7.00e+00 1.10e+01 0.00e+00 2.00e+00 1.00e+00\n",
      " 2.70e+01 1.40e+01 0.00e+00 2.00e+00 5.00e+00 1.00e+00 1.80e+01 7.00e+00\n",
      " 2.90e+01 1.00e+00 1.70e+01 1.00e+01 7.00e+00 3.00e+00 0.00e+00 4.00e+00\n",
      " 6.00e+00 2.00e+00 2.00e+00 3.80e+01 3.30e+01 1.70e+01 6.00e+00 7.00e+00\n",
      " 7.00e+00 5.00e+00 1.30e+01 1.70e+01 2.00e+01 1.00e+01 5.00e+00 1.10e+01\n",
      " 6.00e+00 3.00e+00 5.00e+00 7.00e+00 0.00e+00 8.00e+00 1.00e+00 6.00e+00\n",
      " 6.00e+00 1.00e+00 1.60e+01 3.00e+00 2.00e+00 0.00e+00 1.00e+00 4.00e+00\n",
      " 5.00e+00 0.00e+00 1.40e+01 5.00e+00 4.00e+00 1.20e+01 4.00e+00 1.20e+01\n",
      " 5.00e+00 5.00e+00 1.70e+01 0.00e+00 1.00e+00 2.00e+00 2.00e+00 2.00e+01\n",
      " 2.00e+00 2.00e+00 2.90e+01 1.00e+00 2.00e+00 1.00e+00 2.00e+00 4.00e+00\n",
      " 2.00e+00 9.00e+00 1.20e+01 2.00e+00 1.00e+00 5.00e+00 2.40e+01 6.00e+00\n",
      " 3.00e+00 5.00e+00 3.00e+00 6.00e+00 1.00e+00 1.00e+00 0.00e+00 2.00e+00\n",
      " 3.00e+00 4.00e+00 9.00e+00 4.00e+00 0.00e+00 3.00e+00 2.00e+00 0.00e+00\n",
      " 1.00e+00 1.00e+00 4.00e+00 8.00e+00 1.00e+00 3.00e+00 1.30e+01 3.00e+00\n",
      " 5.00e+00 2.00e+00 2.00e+00 0.00e+00 3.00e+00 1.00e+00 1.00e+00 2.00e+00\n",
      " 0.00e+00 3.00e+00 4.00e+00 1.00e+00 1.00e+00 4.00e+00 0.00e+00 3.00e+00\n",
      " 5.00e+00 5.00e+00 2.00e+00 7.00e+00 3.00e+00 1.10e+01 8.00e+00 7.00e+00\n",
      " 2.00e+00 1.00e+00 1.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00 3.00e+00\n",
      " 0.00e+00 1.00e+00 1.00e+00 0.00e+00 2.00e+00 1.00e+00 0.00e+00 0.00e+00\n",
      " 0.00e+00 0.00e+00 0.00e+00 2.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      " 0.00e+00 1.00e+00 0.00e+00 1.00e+00 1.00e+00 2.00e+00 3.00e+00 3.00e+00\n",
      " 1.00e+00 2.00e+00 2.00e+00 1.00e+00 1.00e+00 4.00e+00 6.00e+00 1.00e+00\n",
      " 0.00e+00 2.00e+00 0.00e+00 0.00e+00 1.00e+00 3.00e+00 2.00e+00 1.00e+00\n",
      " 6.00e+00 4.00e+00 2.00e+00 1.00e+00 3.00e+00 1.00e+00 0.00e+00 0.00e+00\n",
      " 1.00e+00 1.00e+00 0.00e+00 4.00e+00 1.00e+00 0.00e+00 1.00e+00 0.00e+00\n",
      " 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00 0.00e+00\n",
      " 3.00e+00 1.00e+00 7.00e+00 6.00e+00 1.00e+00 1.00e+00 2.00e+00 0.00e+00\n",
      " 0.00e+00 1.00e+00 0.00e+00 3.00e+00 0.00e+00 3.00e+00 2.00e+00 0.00e+00\n",
      " 3.00e+00 0.00e+00 1.00e+00 0.00e+00 0.00e+00 1.00e+00 1.00e+00 1.00e+00\n",
      " 2.00e+00 0.00e+00 0.00e+00 2.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00\n",
      " 4.00e+00 0.00e+00 1.00e+00 2.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      " 1.00e+00 0.00e+00 0.00e+00 1.00e+00 1.00e+00 0.00e+00 1.00e+00 0.00e+00\n",
      " 3.00e+00 2.00e+00 3.00e+00 2.00e+00 2.00e+00 1.00e+00 1.00e+00 0.00e+00\n",
      " 0.00e+00 0.00e+00 2.00e+00 0.00e+00 4.00e+00 1.00e+00 3.00e+00 1.00e+00\n",
      " 1.00e+00]\n",
      "Total labels in full dataset: 40331.0\n",
      "Per-tag label count: [2.858e+03 1.369e+03 1.572e+03 3.770e+03 2.160e+02 1.207e+03 3.900e+02\n",
      " 1.167e+03 1.318e+03 2.918e+03 2.943e+03 2.394e+03 2.900e+01 3.400e+01\n",
      " 6.300e+01 7.300e+01 3.010e+02 2.210e+02 1.174e+03 1.284e+03 1.105e+03\n",
      " 6.800e+02 3.300e+01 6.540e+02 5.800e+01 5.470e+02 1.600e+02 1.000e+00\n",
      " 2.260e+02 2.200e+01 4.190e+02 1.780e+02 8.600e+01 1.390e+02 8.500e+01\n",
      " 1.670e+02 1.580e+02 2.760e+02 2.880e+02 1.120e+02 5.700e+01 1.640e+02\n",
      " 5.300e+01 1.010e+02 1.700e+01 5.200e+01 1.040e+02 2.000e+00 0.000e+00\n",
      " 1.000e+00 8.800e+01 2.200e+01 2.000e+01 2.900e+01 1.170e+02 1.880e+02\n",
      " 1.060e+02 6.100e+01 8.800e+01 2.770e+02 2.000e+01 2.200e+01 2.700e+01\n",
      " 2.500e+01 2.000e+01 2.100e+01 2.100e+01 1.500e+01 2.700e+01 6.500e+01\n",
      " 5.200e+01 7.900e+01 4.000e+00 3.000e+00 1.900e+01 2.300e+01 1.740e+02\n",
      " 1.470e+02 6.600e+01 7.000e+01 0.000e+00 8.000e+00 5.000e+00 4.000e+00\n",
      " 1.160e+02 1.000e+01 7.000e+00 9.000e+00 1.140e+02 1.340e+02 2.700e+01\n",
      " 2.800e+01 3.900e+01 1.000e+01 1.410e+02 9.900e+01 1.220e+02 1.300e+01\n",
      " 1.980e+02 1.120e+02 1.100e+02 9.700e+01 8.000e+00 1.000e+02 3.300e+01\n",
      " 9.000e+00 1.000e+01 1.160e+02 1.280e+02 5.000e+01 4.000e+01 3.600e+01\n",
      " 1.590e+02 1.160e+02 9.800e+01 1.090e+02 1.130e+02 3.600e+01 5.600e+01\n",
      " 1.070e+02 6.900e+01 1.000e+01 8.700e+01 6.500e+01 8.000e+00 5.600e+01\n",
      " 7.000e+00 5.700e+01 7.300e+01 6.000e+00 2.800e+01 2.300e+01 1.700e+01\n",
      " 2.000e+01 1.400e+01 2.000e+01 3.500e+01 5.000e+00 1.010e+02 3.600e+01\n",
      " 8.000e+00 7.900e+01 2.500e+01 9.100e+01 3.000e+01 5.500e+01 3.100e+01\n",
      " 7.000e+00 2.300e+01 7.000e+00 1.200e+01 1.260e+02 2.300e+01 1.700e+01\n",
      " 3.600e+01 2.100e+01 5.700e+01 7.000e+00 3.500e+01 3.000e+00 8.000e+00\n",
      " 9.000e+00 5.000e+00 3.000e+00 8.000e+00 3.000e+01 1.290e+02 6.500e+01\n",
      " 4.000e+00 7.700e+01 4.400e+01 8.000e+00 9.000e+00 1.400e+01 3.000e+00\n",
      " 4.900e+01 4.900e+01 1.190e+02 1.170e+02 1.230e+02 5.500e+01 1.000e+01\n",
      " 1.600e+01 1.700e+01 2.700e+01 4.100e+01 3.500e+01 2.600e+01 2.600e+01\n",
      " 3.500e+01 9.200e+01 1.000e+00 3.000e+00 7.400e+01 1.400e+01 2.100e+01\n",
      " 1.700e+01 1.000e+01 6.000e+00 2.600e+01 9.000e+00 1.900e+01 4.200e+01\n",
      " 3.200e+01 1.600e+01 3.400e+01 5.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      " 7.000e+00 6.000e+01 1.600e+01 2.500e+01 3.400e+01 1.200e+01 3.000e+00\n",
      " 3.000e+00 3.000e+00 1.500e+01 1.000e+00 2.000e+00 5.000e+00 1.500e+01\n",
      " 8.000e+00 8.000e+00 1.200e+01 1.400e+01 1.900e+01 2.600e+01 1.600e+01\n",
      " 8.000e+00 5.000e+00 7.000e+00 9.000e+00 1.800e+01 8.000e+00 5.000e+00\n",
      " 8.000e+00 2.000e+00 8.000e+00 1.100e+01 7.000e+00 1.900e+01 0.000e+00\n",
      " 1.000e+00 1.000e+00 1.000e+00 9.000e+00 9.000e+00 5.000e+00 2.400e+01\n",
      " 1.600e+01 6.000e+00 4.400e+01 1.000e+01 5.000e+00 2.000e+01 6.000e+00\n",
      " 1.600e+01 2.000e+01 1.000e+00 3.600e+01 1.600e+01 3.000e+00 5.000e+00\n",
      " 7.000e+00 1.400e+01 1.300e+01 7.000e+00 1.100e+01 1.600e+01 3.100e+01\n",
      " 2.900e+01 2.200e+01 1.900e+01 1.100e+01 8.000e+00 1.100e+01 5.000e+00\n",
      " 7.000e+00 8.000e+00 8.000e+00 8.000e+00 1.100e+01 7.000e+00 4.000e+00\n",
      " 5.000e+00 2.200e+01 9.000e+00 4.200e+01 3.000e+00 1.000e+00 0.000e+00\n",
      " 1.500e+01 0.000e+00 1.000e+01 7.000e+00 5.000e+00 2.700e+01 8.000e+00\n",
      " 2.600e+01 3.000e+00 1.200e+01 4.000e+00 1.100e+01 8.000e+00 2.000e+00\n",
      " 5.000e+00 1.400e+01 7.000e+00 3.000e+00 1.500e+01 3.000e+00 8.000e+00\n",
      " 8.000e+00 1.300e+01 1.900e+01 2.000e+00 3.000e+00 8.000e+00 2.000e+00\n",
      " 8.000e+00 8.000e+00 5.000e+00 1.100e+01 7.000e+00 4.000e+00 1.100e+01\n",
      " 1.000e+01 1.000e+00 9.000e+00 3.000e+00 5.000e+00 2.000e+00 6.000e+00\n",
      " 3.000e+00 1.500e+01 1.000e+01 5.000e+00 8.000e+00 6.000e+00 7.000e+00\n",
      " 5.000e+00 6.000e+00 4.000e+00 5.000e+00 3.000e+00 1.000e+00 3.000e+00\n",
      " 9.000e+00 2.000e+00 8.000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total labels in full dataset:\", Y_preds.sum())\n",
    "print(\"Per-tag label count:\", y_test.sum(axis=0))\n",
    "\n",
    "print(\"Total labels in full dataset:\", Y.sum())\n",
    "print(\"Per-tag label count:\", Y.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8291 8291 8291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.0037687287357157334\n",
      "Macro Precision: 0.00199813921577136\n",
      "Macro Recall: 0.2096317280453258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jotan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Macro = average over tags, treating each equally\n",
    "print(len(y_test), len(Y_preds), len(X_test))\n",
    "f1 = f1_score(y_test, Y_preds, average='macro')\n",
    "precision = precision_score(y_test, Y_preds, average='macro')\n",
    "recall = recall_score(y_test, Y_preds, average='macro')\n",
    "\n",
    "print(\"Macro F1 Score:\", f1)\n",
    "print(\"Macro Precision:\", precision)\n",
    "print(\"Macro Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10198a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "    #print(f\"Prediction = {Y_preds[i]} \\t Actual = {y_test[i]}\")\n",
    "    #print(f\"length pred = {len(Y_preds[i])} \\t len actual = {len(y_test[i])}\")\n",
    "    if len(Y_preds[i]) != len(y_test[i]):\n",
    "        print(\"oops\")\n",
    "        print(i)\n",
    "\n",
    "#print(len(Y_preds))\n",
    "#print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e670c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      1.00      0.10       421\n",
      "           1       0.00      0.00      0.00       779\n",
      "           2       0.10      1.00      0.18       840\n",
      "           3       0.14      1.00      0.25      1170\n",
      "           4       0.00      0.00      0.00        13\n",
      "           5       0.02      1.00      0.04       179\n",
      "           6       0.00      1.00      0.01        35\n",
      "           7       0.02      1.00      0.05       195\n",
      "           8       0.03      1.00      0.07       286\n",
      "           9       0.06      1.00      0.12       509\n",
      "          10       0.06      1.00      0.11       488\n",
      "          11       0.00      0.00      0.00       304\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.00      1.00      0.00        10\n",
      "          15       0.00      1.00      0.00        11\n",
      "          16       0.00      1.00      0.01        33\n",
      "          17       0.00      1.00      0.01        29\n",
      "          18       0.02      1.00      0.04       180\n",
      "          19       0.00      0.00      0.00       147\n",
      "          20       0.00      0.00      0.00       115\n",
      "          21       0.00      0.00      0.00       105\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.01      1.00      0.03       121\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.01      1.00      0.02       100\n",
      "          26       0.00      0.00      0.00        41\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       0.01      1.00      0.01        55\n",
      "          29       0.00      1.00      0.00         6\n",
      "          30       0.01      1.00      0.02        83\n",
      "          31       0.00      1.00      0.01        24\n",
      "          32       0.00      0.00      0.00        11\n",
      "          33       0.00      0.00      0.00        10\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      1.00      0.01        22\n",
      "          36       0.00      0.00      0.00        15\n",
      "          37       0.01      1.00      0.01        50\n",
      "          38       0.00      1.00      0.01        37\n",
      "          39       0.00      0.00      0.00        24\n",
      "          40       0.01      1.00      0.02        94\n",
      "          41       0.02      1.00      0.04       159\n",
      "          42       0.01      1.00      0.02        69\n",
      "          43       0.00      0.00      0.00        67\n",
      "          44       0.00      0.00      0.00        17\n",
      "          45       0.00      0.00      0.00         4\n",
      "          46       0.00      0.00      0.00        17\n",
      "          47       0.00      1.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.01      1.00      0.02        76\n",
      "          51       0.00      1.00      0.00        12\n",
      "          52       0.00      0.00      0.00        15\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      1.00      0.01        32\n",
      "          55       0.00      1.00      0.01        34\n",
      "          56       0.00      0.00      0.00        11\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.00      0.00      0.00         7\n",
      "          59       0.01      1.00      0.02        85\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         2\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.00      1.00      0.00         4\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      1.00      0.00         4\n",
      "          69       0.00      1.00      0.00        13\n",
      "          70       0.00      1.00      0.00         3\n",
      "          71       0.00      0.00      0.00        12\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         5\n",
      "          75       0.00      1.00      0.00        15\n",
      "          76       0.00      1.00      0.01        23\n",
      "          77       0.00      0.00      0.00        19\n",
      "          78       0.00      1.00      0.00         7\n",
      "          79       0.00      0.00      0.00        13\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         8\n",
      "          82       0.00      1.00      0.00         3\n",
      "          83       0.00      0.00      0.00         7\n",
      "          84       0.00      1.00      0.00        11\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      1.00      0.00         2\n",
      "          87       0.00      1.00      0.00         1\n",
      "          88       0.00      1.00      0.01        27\n",
      "          89       0.00      0.00      0.00        14\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         5\n",
      "          93       0.00      0.00      0.00         1\n",
      "          94       0.00      0.00      0.00        18\n",
      "          95       0.00      0.00      0.00         7\n",
      "          96       0.00      1.00      0.01        29\n",
      "          97       0.00      1.00      0.00         1\n",
      "          98       0.00      1.00      0.00        17\n",
      "          99       0.00      0.00      0.00        10\n",
      "         100       0.00      0.00      0.00         7\n",
      "         101       0.00      1.00      0.00         3\n",
      "         102       0.00      0.00      0.00         0\n",
      "         103       0.00      0.00      0.00         4\n",
      "         104       0.00      1.00      0.00         6\n",
      "         105       0.00      1.00      0.00         2\n",
      "         106       0.00      0.00      0.00         2\n",
      "         107       0.00      1.00      0.01        38\n",
      "         108       0.00      1.00      0.01        33\n",
      "         109       0.00      1.00      0.00        17\n",
      "         110       0.00      0.00      0.00         6\n",
      "         111       0.00      0.00      0.00         7\n",
      "         112       0.00      1.00      0.00         7\n",
      "         113       0.00      0.00      0.00         5\n",
      "         114       0.00      0.00      0.00        13\n",
      "         115       0.00      0.00      0.00        17\n",
      "         116       0.00      1.00      0.00        20\n",
      "         117       0.00      0.00      0.00        10\n",
      "         118       0.00      0.00      0.00         5\n",
      "         119       0.00      1.00      0.00        11\n",
      "         120       0.00      1.00      0.00         6\n",
      "         121       0.00      0.00      0.00         3\n",
      "         122       0.00      1.00      0.00         5\n",
      "         123       0.00      0.00      0.00         7\n",
      "         124       0.00      0.00      0.00         0\n",
      "         125       0.00      0.00      0.00         8\n",
      "         126       0.00      1.00      0.00         1\n",
      "         127       0.00      0.00      0.00         6\n",
      "         128       0.00      0.00      0.00         6\n",
      "         129       0.00      0.00      0.00         1\n",
      "         130       0.00      1.00      0.00        16\n",
      "         131       0.00      1.00      0.00         3\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      1.00      0.00         4\n",
      "         136       0.00      1.00      0.00         5\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       0.00      0.00      0.00        14\n",
      "         139       0.00      0.00      0.00         5\n",
      "         140       0.00      0.00      0.00         4\n",
      "         141       0.00      0.00      0.00        12\n",
      "         142       0.00      0.00      0.00         4\n",
      "         143       0.00      0.00      0.00        12\n",
      "         144       0.00      0.00      0.00         5\n",
      "         145       0.00      0.00      0.00         5\n",
      "         146       0.00      0.00      0.00        17\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         2\n",
      "         150       0.00      1.00      0.00         2\n",
      "         151       0.00      0.00      0.00        20\n",
      "         152       0.00      0.00      0.00         2\n",
      "         153       0.00      0.00      0.00         2\n",
      "         154       0.00      0.00      0.00        29\n",
      "         155       0.00      0.00      0.00         1\n",
      "         156       0.00      0.00      0.00         2\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         2\n",
      "         159       0.00      0.00      0.00         4\n",
      "         160       0.00      0.00      0.00         2\n",
      "         161       0.00      0.00      0.00         9\n",
      "         162       0.00      0.00      0.00        12\n",
      "         163       0.00      0.00      0.00         2\n",
      "         164       0.00      0.00      0.00         1\n",
      "         165       0.00      0.00      0.00         5\n",
      "         166       0.00      1.00      0.01        24\n",
      "         167       0.00      0.00      0.00         6\n",
      "         168       0.00      0.00      0.00         3\n",
      "         169       0.00      0.00      0.00         5\n",
      "         170       0.00      0.00      0.00         3\n",
      "         171       0.00      0.00      0.00         6\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         2\n",
      "         176       0.00      0.00      0.00         3\n",
      "         177       0.00      0.00      0.00         4\n",
      "         178       0.00      0.00      0.00         9\n",
      "         179       0.00      0.00      0.00         4\n",
      "         180       0.00      0.00      0.00         0\n",
      "         181       0.00      1.00      0.00         3\n",
      "         182       0.00      0.00      0.00         2\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         1\n",
      "         186       0.00      0.00      0.00         4\n",
      "         187       0.00      0.00      0.00         8\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       0.00      0.00      0.00         3\n",
      "         190       0.00      0.00      0.00        13\n",
      "         191       0.00      0.00      0.00         3\n",
      "         192       0.00      0.00      0.00         5\n",
      "         193       0.00      0.00      0.00         2\n",
      "         194       0.00      0.00      0.00         2\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       0.00      0.00      0.00         3\n",
      "         197       0.00      0.00      0.00         1\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         2\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         3\n",
      "         202       0.00      1.00      0.00         4\n",
      "         203       0.00      0.00      0.00         1\n",
      "         204       0.00      0.00      0.00         1\n",
      "         205       0.00      0.00      0.00         4\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         3\n",
      "         208       0.00      0.00      0.00         5\n",
      "         209       0.00      0.00      0.00         5\n",
      "         210       0.00      1.00      0.00         2\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       0.00      0.00      0.00         3\n",
      "         213       0.00      1.00      0.00        11\n",
      "         214       0.00      0.00      0.00         8\n",
      "         215       0.00      1.00      0.00         7\n",
      "         216       0.00      0.00      0.00         2\n",
      "         217       0.00      0.00      0.00         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         0\n",
      "         220       0.00      0.00      0.00         0\n",
      "         221       0.00      1.00      0.00         1\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         3\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         2\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         0\n",
      "         231       0.00      0.00      0.00         0\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         0\n",
      "         235       0.00      0.00      0.00         2\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         0\n",
      "         239       0.00      0.00      0.00         0\n",
      "         240       0.00      0.00      0.00         0\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         0\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       0.00      0.00      0.00         2\n",
      "         246       0.00      0.00      0.00         3\n",
      "         247       0.00      0.00      0.00         3\n",
      "         248       0.00      1.00      0.00         1\n",
      "         249       0.00      0.00      0.00         2\n",
      "         250       0.00      0.00      0.00         2\n",
      "         251       0.00      0.00      0.00         1\n",
      "         252       0.00      0.00      0.00         1\n",
      "         253       0.00      0.00      0.00         4\n",
      "         254       0.00      0.00      0.00         6\n",
      "         255       0.00      0.00      0.00         1\n",
      "         256       0.00      0.00      0.00         0\n",
      "         257       0.00      0.00      0.00         2\n",
      "         258       0.00      0.00      0.00         0\n",
      "         259       0.00      0.00      0.00         0\n",
      "         260       0.00      0.00      0.00         1\n",
      "         261       0.00      0.00      0.00         3\n",
      "         262       0.00      0.00      0.00         2\n",
      "         263       0.00      0.00      0.00         1\n",
      "         264       0.00      1.00      0.00         6\n",
      "         265       0.00      0.00      0.00         4\n",
      "         266       0.00      0.00      0.00         2\n",
      "         267       0.00      0.00      0.00         1\n",
      "         268       0.00      0.00      0.00         3\n",
      "         269       0.00      0.00      0.00         1\n",
      "         270       0.00      0.00      0.00         0\n",
      "         271       0.00      0.00      0.00         0\n",
      "         272       0.00      0.00      0.00         1\n",
      "         273       0.00      0.00      0.00         1\n",
      "         274       0.00      0.00      0.00         0\n",
      "         275       0.00      1.00      0.00         4\n",
      "         276       0.00      0.00      0.00         1\n",
      "         277       0.00      0.00      0.00         0\n",
      "         278       0.00      0.00      0.00         1\n",
      "         279       0.00      0.00      0.00         0\n",
      "         280       0.00      0.00      0.00         0\n",
      "         281       0.00      0.00      0.00         0\n",
      "         282       0.00      0.00      0.00         0\n",
      "         283       0.00      0.00      0.00         0\n",
      "         284       0.00      0.00      0.00         0\n",
      "         285       0.00      0.00      0.00         1\n",
      "         286       0.00      0.00      0.00         0\n",
      "         287       0.00      0.00      0.00         0\n",
      "         288       0.00      0.00      0.00         3\n",
      "         289       0.00      0.00      0.00         1\n",
      "         290       0.00      0.00      0.00         7\n",
      "         291       0.00      0.00      0.00         6\n",
      "         292       0.00      0.00      0.00         1\n",
      "         293       0.00      0.00      0.00         1\n",
      "         294       0.00      0.00      0.00         2\n",
      "         295       0.00      0.00      0.00         0\n",
      "         296       0.00      0.00      0.00         0\n",
      "         297       0.00      0.00      0.00         1\n",
      "         298       0.00      0.00      0.00         0\n",
      "         299       0.00      0.00      0.00         3\n",
      "         300       0.00      0.00      0.00         0\n",
      "         301       0.00      0.00      0.00         3\n",
      "         302       0.00      0.00      0.00         2\n",
      "         303       0.00      0.00      0.00         0\n",
      "         304       0.00      0.00      0.00         3\n",
      "         305       0.00      0.00      0.00         0\n",
      "         306       0.00      0.00      0.00         1\n",
      "         307       0.00      0.00      0.00         0\n",
      "         308       0.00      0.00      0.00         0\n",
      "         309       0.00      0.00      0.00         1\n",
      "         310       0.00      0.00      0.00         1\n",
      "         311       0.00      0.00      0.00         1\n",
      "         312       0.00      0.00      0.00         2\n",
      "         313       0.00      0.00      0.00         0\n",
      "         314       0.00      0.00      0.00         0\n",
      "         315       0.00      0.00      0.00         2\n",
      "         316       0.00      0.00      0.00         0\n",
      "         317       0.00      0.00      0.00         0\n",
      "         318       0.00      0.00      0.00         1\n",
      "         319       0.00      0.00      0.00         0\n",
      "         320       0.00      0.00      0.00         4\n",
      "         321       0.00      0.00      0.00         0\n",
      "         322       0.00      0.00      0.00         1\n",
      "         323       0.00      0.00      0.00         2\n",
      "         324       0.00      0.00      0.00         0\n",
      "         325       0.00      0.00      0.00         0\n",
      "         326       0.00      0.00      0.00         0\n",
      "         327       0.00      0.00      0.00         0\n",
      "         328       0.00      0.00      0.00         1\n",
      "         329       0.00      0.00      0.00         0\n",
      "         330       0.00      0.00      0.00         0\n",
      "         331       0.00      0.00      0.00         1\n",
      "         332       0.00      0.00      0.00         1\n",
      "         333       0.00      0.00      0.00         0\n",
      "         334       0.00      0.00      0.00         1\n",
      "         335       0.00      0.00      0.00         0\n",
      "         336       0.00      0.00      0.00         3\n",
      "         337       0.00      0.00      0.00         2\n",
      "         338       0.00      0.00      0.00         3\n",
      "         339       0.00      0.00      0.00         2\n",
      "         340       0.00      0.00      0.00         2\n",
      "         341       0.00      0.00      0.00         1\n",
      "         342       0.00      0.00      0.00         1\n",
      "         343       0.00      0.00      0.00         0\n",
      "         344       0.00      0.00      0.00         0\n",
      "         345       0.00      0.00      0.00         0\n",
      "         346       0.00      0.00      0.00         2\n",
      "         347       0.00      0.00      0.00         0\n",
      "         348       0.00      0.00      0.00         4\n",
      "         349       0.00      0.00      0.00         1\n",
      "         350       0.00      0.00      0.00         3\n",
      "         351       0.00      0.00      0.00         1\n",
      "         352       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.01      0.71      0.02      8281\n",
      "   macro avg       0.00      0.21      0.00      8281\n",
      "weighted avg       0.04      0.71      0.08      8281\n",
      " samples avg       0.01      0.71      0.02      8281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, Y_preds, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
